{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d12f333",
   "metadata": {},
   "source": [
    "# Analysis of the spatial structure of connectivity in the MICrONS dataset\n",
    "\n",
    "The MICrONS initiative provided a dense reconstruction of around a cubic milimeter of mouse brain tissue.\n",
    "\n",
    "At OBI, we have converted that data into the SONATA format that is often used to represent biophysically-detailed computational models of neuronal circuitry. We believe that this is a useful resource for the community for the following reasons:\n",
    " 1. It allows direct comparison of models to the data, as both are in the same format. In the future it may even be possible to simulate the MICrONS circuitry as one simulates the computational models.\n",
    " 2. There are many useful code libraries for analyzing SONATA-formatted circuits.\n",
    " 3. It is reduced representation of the data. While this discards a lot of information, what remains is still very useful for many purposes. And the reduced data can be more easily handled and analyzed faster.\n",
    " 4. During the conversion to SONATA we added derived data. Specifically, high-quality morphology skeletons with extracted spines.\n",
    "\n",
    "\n",
    "Here, we want to expand on point (3) above. \n",
    "\n",
    "We use the data to test our hypothesis about the mechanisms that allow individual neuron morphologies to leads to structured, non-random synaptic connectivity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a859ec9c",
   "metadata": {},
   "source": [
    "### Summary of the analysis\n",
    "\n",
    "It has been demonstrated before, that modeled networks based on axo-dendritic touch generate a highly non-random structure that matches biological characteristics better than simpler, connection probability-based models. Such characteristics are for example degree distributions, and motif overexpression patterns.\n",
    "\n",
    "We formulate a hypothesis of what mechanism leads to this and test it using the MICrONS data. The hypothesis is as follows:\n",
    "\n",
    "  1. A required (although not sufficient) condition for the formation of a connection is proximity of the axon to the dendrite\n",
    "  2. This condition can in principle be formulated as a distance and direction-dependent probability function on the offset between somata of a neuron pair. \n",
    "  3. The shape of this function is determined by the overall average shape of the dendrites and axons of the classes of neurons considered.\n",
    "  4. However, once a connection at a given distance and direction has been confirmed for a given pre-/post-synaptic neuron, this function must be updated for all its future potential connections. This is because presence of the connection demonstrates that the axon / dendrites are more likely to be oriented towards the point where the connection has been formed.\n",
    "  5. On a theoretical level, this introduces a _statistical dependence_ between connections: Presence or absence of one connection influences the probability that another connection is present. This is something that connection probability-dependent models, even complex ones, cannot capture, as they are based on statistically independent evaluations of connection probabilities.\n",
    "\n",
    "We consider points 1-3 to be widely accepted. Points 4 and 5 describe aplausible scenario. But we have to demonstrate that the proposed mechanism actually affects connectivity on a measurable level. To do so, we test a prediction derived from the hypothesis.\n",
    "\n",
    "**Prediction**: If a neuron A innervates / is innervated by a neuron B, then the probability that it also innervates / is innervated by the _nearest spatial neighbor_ of B is increased."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb27d790",
   "metadata": {},
   "source": [
    "## Importing code libraries and loading the data\n",
    "\n",
    "We import a number of standard packages, as well as _conntility_ and _connalysis_. These two packages provide (as we will see) useful functionality for the analysis of this type of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a660f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import conntility\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "numpy.seterr(all=\"ignore\")\n",
    "\n",
    "\n",
    "fn = \"../../../../shared_data/MICrONS_SONATA/microns_con_mat_multi.h5\"\n",
    "\n",
    "# We load the data that has been serialized into a single hdf5 file into an object.\n",
    "M = conntility.ConnectivityMatrix.from_h5(fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a885e2f3",
   "metadata": {},
   "source": [
    "### Side note: data representation\n",
    "\n",
    "The data, that is, the neurons and their connections, are represented in the object M. \n",
    "The representation has a list of _vertices_, i.e. neurons, and _edges_, i.e. synaptic connections. \n",
    "\n",
    "We can list the vertices and their properties.\n",
    "Important properties for this analysis are:\n",
    "  - layer, a string indicating the cortical layer of each neuron\n",
    "  - synapse_class, this is either \"EXC\" or \"INH\" indicating that a neuron is excitatory or inhibitory\n",
    "  - x, y, z, the spatial locations of the neurons in um"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d72a77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(M.vertices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cac385",
   "metadata": {},
   "source": [
    "We can also list the edges and their properties.\n",
    "For the purpose of this analysis, we do not consider the properties at all - we are only interested in the presence or absence of a connection. Still, other analyses can use the properties.\n",
    "\n",
    "For example, \"spine_id\" lists an identifier of the spine that a synapse innervates, or -1 for shaft synapses. Note that we have only identified spines for a subset of postsynaptic neurons, and for the rest all afferent synapses list a value of -1. We are working on extending the number of neurons with identified spines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dce8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(M.edges.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945e366f",
   "metadata": {},
   "source": [
    "## Select the excitatory sub-graph\n",
    "\n",
    "It is quite accepted that connectivity of inhibitory neurons follows quite different rules than excitatory connectivity. \n",
    "Hence, we limit our analysis here to only the excitatory subgraph, for simplicity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ce650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subcircuit using the .index functionality. The following creates the subcircuit of neurons where \n",
    "# the values of \"synapse_class\" is equal to \"EXC\".\n",
    "M = M.index(\"synapse_class\").eq(\"EXC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3db96bf",
   "metadata": {},
   "source": [
    "## Finding the nearest neighbors\n",
    "To find the nearest neighbors of each neuron, we use a specialized data structure called a KDTree, implemented in scipy. It takes as input the spatial coordinates (i.e., the \"x\", \"y\" and \"z\" properties) of all neurons.\n",
    "\n",
    "Specifically, we build a numpy.array with one entry per neuron, where the entry at index i yields the index of the nearest neighbor of the ith neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e41314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree\n",
    "\n",
    "xyz = [\"x\", \"y\", \"z\"]\n",
    "# Build KDTree\n",
    "tree = KDTree(M.vertices[xyz])\n",
    "\n",
    "# Query KDTree for nearest neighbor. [2] indicates we ask for the 2nd nearest neighbor. This is, because the neuron itself\n",
    "# is not excluded from this query and will be the 1st nearest neighbor with a distance of 0\n",
    "nn_dists, nn_idx = tree.query(M.vertices[xyz], [2])\n",
    "nn_idx = nn_idx.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a96c7df",
   "metadata": {},
   "source": [
    "### Small detour: plot nearest neighbor distances\n",
    "\n",
    "Just as a quick sanity check and out of curiosity, we plot a histogram of the distances to the nearest neighbor of each neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11597fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = numpy.histogram(nn_dists, bins=15)\n",
    "plt.bar(H[1][:-1], H[0], width=numpy.mean(numpy.diff(H[1])))\n",
    "plt.gca().set_xlabel(\"Nearest neighbor distance (um)\")\n",
    "plt.gca().set_ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccc6e98",
   "metadata": {},
   "source": [
    "# Main analysis\n",
    "\n",
    "Now, we perform the main analysis. \n",
    "As we have ~50,000 neurons in the dataset, we have ~2,500,000,000 pairs of potentially connected neurons. While it is still viable to iterate in analyses over that number of pairs, it is also highly inefficient. \n",
    "\n",
    "Instead, I will implement a more efficient form of the analysis.\n",
    "\n",
    "We begin by assembling a DataFrame with one row per **connected** pair. Its columns are as follows:\n",
    "  - \"row\": Index of the pre-synaptic neuron of the connection\n",
    "  - \"col\": Index of the post-synaptic neuron of the connection\n",
    "  - \"nn_row\": Index of the nearest neighbor of the pre-synaptic neuron\n",
    "  - \"nn_col\": Index of the nearest neighbor of the post-synaptic neuron\n",
    "  - \"dx\", \"dy\", \"dz\": Offset along the spatial axes of the pair locations.\n",
    "  - \"1d_dist\": Distance (1-dimensional) of between the neurons of the pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7435a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns \"row\", and \"col\" are already part of the data structure we loaded inititally. \n",
    "edge_df = M._edge_indices.copy().reset_index(drop=True)\n",
    "\n",
    "# We can then look up \"nn_row\", \"nn_col\" from the array we assembled earlier\n",
    "edge_df[\"nn_col\"] = nn_idx[M._edge_indices[\"col\"]]\n",
    "edge_df[\"nn_row\"] = nn_idx[M._edge_indices[\"row\"]]\n",
    "\n",
    "# M provides a function that yields for each connection the \"x\", \"y\" or \"z\" coordinate of the pre- and post-syn. neurons\n",
    "# We calculate their distances as \"dx\", \"dy\", \"dz\"\n",
    "for col_name in xyz:\n",
    "    per_edge_coords = M.edge_associated_vertex_properties(col_name)\n",
    "    edge_df[\"d\" + col_name] = per_edge_coords[\"col\"] - per_edge_coords[\"row\"]\n",
    "\n",
    "# 1-dimensional distance is easily calculated\n",
    "xyz_delta = [\"dx\", \"dy\", \"dz\"]\n",
    "edge_df[\"1d_dist\"] = numpy.linalg.norm(edge_df[xyz_delta], axis=1)\n",
    "\n",
    "display(edge_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc6607c",
   "metadata": {},
   "source": [
    "This allows us to easily look up connection probabilities from the adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d67172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjacency matrix. Efficiently represented as a sparse matrix with bool entries\n",
    "actual_con = M.matrix.tocsc().astype(bool)\n",
    "\n",
    "# Note that each row of the DataFrame represents one instance where the nearest neighbor of neuron B is connected to A.\n",
    "# Hence, we can use to easily look up the probability that B is also connected to A.\n",
    "post_nn_con_mean = actual_con[edge_df[\"row\"], edge_df[\"nn_col\"]].mean()\n",
    "pre_nn_con_mean = actual_con[edge_df[\"nn_row\"], edge_df[\"col\"]].mean()\n",
    "\n",
    "print(f\"\"\"Overall connection probability: {actual_con.mean()},\n",
    "      If post-synaptic nearest neighbor is connected: {post_nn_con_mean},\n",
    "      if pre-synaptic nearest neighbor is connected: {pre_nn_con_mean}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20becdb2",
   "metadata": {},
   "source": [
    "We see that the connection probability is drastically increased, especially if the post-synaptic nearest neighbor is connected.\n",
    "\n",
    "However, distance-dependence of connectivity can explain (part of) such an effect: The nearest neighbor being connected makes it likely that we are considering a pair of neurons at a low distance. That also increases the probability that the original neuron is connected.\n",
    "\n",
    "## Loading a distance-dependent control\n",
    "\n",
    "To address this, we begin by creating a distance-dependent control connectome. Specifically, we consider the following: For each ordered pair of layers, (L_i, L_j) we fit an exponential function that describes the connection probability from neurons in L_i to neurons in L_j. Then we generate a stochastic instance of that connectome.\n",
    "\n",
    "The fitting would take around 3-5 minutes to run. To speed things up, we have prepared such a control connectome and we simply load it. \n",
    "**Imortantly**, the control connectome was generated on the same nodes with the same locations as the original connectome. So we do not have to re-generate the lookup for nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e30ee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_ctrl = \"../../../../shared_data/MICrONS_SONATA/control_con_mat.h5\"\n",
    "C = conntility.ConnectivityMatrix.from_h5(fn_ctrl)\n",
    "\n",
    "# Make sure the neuron locations really are identical\n",
    "assert (M.vertices[xyz] == C.vertices[xyz]).all().all()\n",
    "# Sparse adjacency matrix\n",
    "control_con = C.matrix.tocsc().astype(bool)\n",
    "\n",
    "post_nn_con_mean = control_con[edge_df[\"row\"], edge_df[\"nn_col\"]].mean()\n",
    "pre_nn_con_mean = control_con[edge_df[\"nn_row\"], edge_df[\"col\"]].mean()\n",
    "\n",
    "print(f\"\"\"Overall connection probability: {control_con.mean()},\n",
    "      If post-synaptic nearest neighbor is connected: {post_nn_con_mean},\n",
    "      if pre-synaptic nearest neighbor is connected: {pre_nn_con_mean}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb9a90a",
   "metadata": {},
   "source": [
    "We see that there is indeed an effect in the distance-dependent control. However, it is sgnificantly weaker than in the actual data.\n",
    "\n",
    "## Making the analysis distance-dependent\n",
    "To control for the effect of distance dependence even further, we repeat the analysis, but separately in 50 um distance bins.\n",
    "\n",
    "To that end, we first need to generate the bins and calculate how many pairs of neurons there are in each bin. Once again, this is valid for both the original data and the control.\n",
    "The KDTree again offers functionality to calculate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf15e858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up bins\n",
    "bin_sz = 50.0\n",
    "# We create the last bin border at a really large distance to ensure that the last bin captures any remaining pair\n",
    "bin_borders = numpy.hstack([numpy.arange(0, 1000 + bin_sz, bin_sz), 1E12])\n",
    "bin_indices = numpy.arange(len(bin_borders) - 1)\n",
    "# Calculate bin centers. For plotting purporses we consider the really large last bin to be \"bin_sz\" distance away from the previous.\n",
    "bin_centers = 0.5 * (bin_borders[:-2] + bin_borders[1:-1])\n",
    "bin_centers = numpy.hstack([bin_centers, bin_centers[-1] + bin_sz])\n",
    "\n",
    "# For each connected pair, we calculate which distance bin it belongs to\n",
    "edge_df[\"1d_dist_bin\"] = numpy.digitize(edge_df[\"1d_dist\"], bins=bin_borders) - 1\n",
    "\n",
    "# The \"count_neighbors\" function yields the numbers of pairs at distances up to and including the queried distance. \n",
    "# That is, it is a cumulative count. We take the .diff to get the non-cumulative numbers in each bin.\n",
    "n_pairs_per_bin = numpy.diff(tree.count_neighbors(tree, bin_borders))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133702a1",
   "metadata": {},
   "source": [
    "Now we can calulate the overall connection probability in each bin. \n",
    "We calculate it simply as the count of connected pairs in a bin, divided by the number of potential pairs in the bin.\n",
    "\n",
    "The connection probabilities conditional on the nearest neighbor being connected we calculate as before. Only this time we perform the analysis separately for each distance bin using the \"groupby\" functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b82e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_con_prob = edge_df.groupby(\"1d_dist_bin\")[\"1d_dist_bin\"].count().reindex(bin_indices) / n_pairs_per_bin\n",
    "\n",
    "con_prob_post_is_connected = edge_df.groupby(\"1d_dist_bin\").apply(lambda _df: actual_con[_df[\"row\"], _df[\"nn_col\"]].mean(),\n",
    "                                                                  include_groups=False)\n",
    "\n",
    "con_prob_pre_is_connected = edge_df.groupby(\"1d_dist_bin\").apply(lambda _df: actual_con[_df[\"nn_row\"], _df[\"col\"]].mean(),\n",
    "                                                                  include_groups=False)\n",
    "\n",
    "\n",
    "plt.plot(bin_centers[prior_con_prob.index], prior_con_prob, color=\"black\", ls=\"--\", label=\"Overall probability\")\n",
    "\n",
    "plt.plot(bin_centers[con_prob_post_is_connected.index], con_prob_post_is_connected, color=\"red\", label=\"If postsyn. NN is connected\")\n",
    "plt.plot(bin_centers[con_prob_pre_is_connected.index], con_prob_pre_is_connected, color=\"blue\", label=\"If presyn. NN is connected\")\n",
    "plt.legend()\n",
    "plt.gca().set_xlabel(\"Distance (um)\")\n",
    "plt.gca().set_ylabel(\"P\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f792a1",
   "metadata": {},
   "source": [
    "Once again, we find a very strong effect. Especially if the post-synaptic neighbor is connected.\n",
    "\n",
    "We repeat the same analysis for the distance-dependent control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9552f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrl_df = C._edge_indices.copy().reset_index(drop=True)\n",
    "\n",
    "ctrl_df[\"nn_col\"] = nn_idx[C._edge_indices[\"col\"]]\n",
    "ctrl_df[\"nn_row\"] = nn_idx[C._edge_indices[\"row\"]]\n",
    "\n",
    "for col_name in xyz:\n",
    "    per_edge_coords = C.edge_associated_vertex_properties(col_name)\n",
    "    ctrl_df[\"d\" + col_name] = per_edge_coords[\"col\"] - per_edge_coords[\"row\"]\n",
    "\n",
    "ctrl_df[\"1d_dist\"] = numpy.linalg.norm(ctrl_df[xyz_delta], axis=1)\n",
    "ctrl_df[\"1d_dist_bin\"] = numpy.digitize(ctrl_df[\"1d_dist\"], bins=bin_borders) - 1\n",
    "\n",
    "\n",
    "\n",
    "ctrl_prior_con_prob = ctrl_df.groupby(\"1d_dist_bin\")[\"1d_dist_bin\"].count() / n_pairs_per_bin\n",
    "\n",
    "ctrl_con_prob_post_is_connected = ctrl_df.groupby(\"1d_dist_bin\").apply(lambda _df: control_con[_df[\"row\"], _df[\"nn_col\"]].mean(),\n",
    "                                                                  include_groups=False)\n",
    "\n",
    "ctrl_con_prob_pre_is_connected = ctrl_df.groupby(\"1d_dist_bin\").apply(lambda _df: control_con[_df[\"nn_row\"], _df[\"col\"]].mean(),\n",
    "                                                                  include_groups=False)\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(bin_centers[ctrl_prior_con_prob.index], ctrl_prior_con_prob, color=\"black\", ls=\"--\", label=\"Overall probability\")\n",
    "\n",
    "plt.plot(bin_centers[ctrl_con_prob_post_is_connected.index], ctrl_con_prob_post_is_connected, color=\"red\",\n",
    "         label=\"If postsyn. NN is connected\")\n",
    "plt.plot(bin_centers[ctrl_con_prob_pre_is_connected.index], ctrl_con_prob_pre_is_connected, color=\"blue\",\n",
    "         label=\"If presyn. NN is connected\")\n",
    "plt.legend()\n",
    "plt.gca().set_xlabel(\"Distance (um)\")\n",
    "plt.gca().set_ylabel(\"P\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6663572f",
   "metadata": {},
   "source": [
    "We find a small to non-existant effect. This indicates that performing the analysis for distance bins separately controls for most of the distance-dependence in the data. \n",
    "\n",
    "### Exercise\n",
    "If you made it this far, the analysis must be of interes to you.\n",
    "As an exercise, we encourage you to implement a version of the analysis with 2-dimensional distance bins instead of merely 1-dimensional ones. One bin indicating the horizontal (\"x\"-\"z\") distance of the pair, the other bin indicating the vertical (\"y\") offset of the pair. \n",
    "\n",
    "There is some interesting spatial structure to this effect that such an analysis captures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entitysdk_notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
